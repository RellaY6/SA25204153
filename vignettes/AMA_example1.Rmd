---
title: "Adaptive Model Averaging (AMA) Example 1 数值实验说明"
author: "SA25204153 杨羽佳"
date: "`r format(Sys.Date(), '%Y-%m-%d')`"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 4
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Adaptive Model Averaging (AMA) Example 1 数值实验说明}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
# NOTE:
# - Do NOT install.packages() inside vignettes.
# - devtools::check() rebuilds vignettes in a clean session/library, so all needed
#   packages should be declared in DESCRIPTION (Imports/Suggests) and installed beforehand.

# ---- Robust package loading for knitting ----
# This Rmd can be knitted in two ways:
# (A) As a normal Rmd outside the package: install the package first; OR
# (B) Inside the package source tree (recommended): we auto-detect the package root
#     and use devtools::load_all() so you do NOT need to install first.

.pkg_root <- function(max_up = 5L) {
  wd <- normalizePath(getwd(), winslash = "/", mustWork = TRUE)
  p <- wd
  for (k in 0:max_up) {
    if (file.exists(file.path(p, "DESCRIPTION"))) return(p)
    parent <- normalizePath(file.path(p, ".."), winslash = "/", mustWork = TRUE)
    if (identical(parent, p)) break
    p <- parent
  }
  return(NA_character_)
}

pkg <- "SA25204153"

if (requireNamespace(pkg, quietly = TRUE)) {
  suppressPackageStartupMessages(library(SA25204153))
} else {
  # Not installed -> try load_all() from package source
  root <- .pkg_root()
  if (is.na(root)) {
    stop(
      "Package 'SA25204153' is not installed, and I cannot find a package root (DESCRIPTION).\n",
      "Fix: (1) open the SA25204153 R project, setwd() to the package root, then Knit; \n",
      "or (2) install the package with devtools::install() and knit again."
    )
  }
  if (!requireNamespace("devtools", quietly = TRUE)) {
    stop("Package 'devtools' is required to knit from source (load_all). Please install it first.")
  }
  suppressPackageStartupMessages(devtools::load_all(root))
}

# Ensure suggested packages for this vignette (should be in DESCRIPTION Suggests/Imports)
need <- c("MASS","lars","quadprog","ggplot2","microbenchmark","knitr")

missing <- need[!vapply(need, requireNamespace, logical(1), quietly = TRUE)]
if (length(missing) > 0) {
  stop("Missing packages needed for this vignette: ", paste(missing, collapse = ", "),
       ". Please install them and re-knit.")
}

suppressPackageStartupMessages({
  library(MASS); library(lars); library(quadprog)
  library(ggplot2); library(microbenchmark); library(knitr)
})
```

# 1. 背景：AMA Example 1 

本小结基于 Zhang (2022) 提出的 **Adaptive Model Averaging (AMA)** 方法，复现文中的 Numerical Example 1。  

- 数据生成：高维线性模型  
  \[
    y = X \beta_0 + \varepsilon,\quad
    X \sim \mathcal{N}(0, \Sigma),\quad
    \varepsilon \sim \mathcal{N}(0, \sigma^2 I_n),
  \]
  其中协方差矩阵 \(\Sigma\) 具有 AR(1) 结构，真系数 \(\beta_0\) 只有前 \(3q\) 个分量非零。

- 目标：比较三种估计方法的模型误差与稀疏性表现：
  1. AMA（自适应模型平均）；
  2. ALASSO + mBIC 单模型选择；
  3. ALASSO + eBIC 单模型选择。

本 R 包实现了 Example 1 中的主要步骤，并提供了 4 个核心函数：

- `ama_fit_example1()`：在给定数据上一条龙跑完 AMA Step 1–6；
- `sim_example1_grid()`：在一组 \((n, \rho, R^2)\) 组合下做 Monte Carlo 模拟比较；
- `compute_ME_cpp()`：在 C++ 中计算模型误差 \(ME(\hat\beta)\)；
- `compute_C_IC_cpp()`：在 C++ 中计算稀疏性指标 C / IC。

下面依次说明这些函数的用途和基本用法。

# 2. 数据生成函数 `gen_example1_data()`

它根据给定的 \((n, \rho, R^2)\) 生成一组模拟数据。

```{r example-gen, echo=TRUE}
dat <- SA25204153:::gen_example1_data(n = 200, rho = 0.5, R2 = 0.4)
str(dat, max.level = 1)
```
```r

gen_example1_data <- function(n, rho = 0.5, R2 = 0.4) {
  ## 1. 维度：p_n = [4 n^{1/2}] - 5
  p <- 4 * floor(sqrt(n)) - 5
  
  ## 2. q = [p_n / 9], 非零个数 |A| = 3q
  q  <- floor(p / 9)
  nonzero <- 3 * q
  stopifnot(nonzero <= p)
  
  ## 3. 协方差矩阵
  idx   <- 1:p
  Sigma <- rho^abs(outer(idx, idx, "-"))
  
  ## 4. 真系数
  beta0 <- c(rep(3, nonzero), rep(0, p - nonzero))
  
  ## 5. 生成 X ~ N(0, Sigma)
  X <- MASS::mvrnorm(n = n, mu = rep(0, p), Sigma = Sigma)
  
  ## 6. 根据 R2 决定噪声方差
  var_signal <- as.numeric(t(beta0) %*% Sigma %*% beta0)
  sigma2     <- var_signal * (1 - R2) / R2
  eps        <- rnorm(n, mean = 0, sd = sqrt(sigma2))
  
  ## 7. 生成 y
  y <- as.numeric(X %*% beta0 + eps)
  
  list(
    X       = X,
    y       = y,
    beta0   = beta0,
    Sigma   = Sigma,
    sigma2  = sigma2,
    p       = p,
    q       = q,
    nonzero = nonzero
  )
}
```
输出列表中包含：

- `X`：\(n \times p\) 设计矩阵；
- `y`：长度为 \(n\) 的响应向量；
- `beta0`：真系数向量；
- `Sigma`：协方差矩阵；
- 以及若干用于描述维度设置的参数。

# 3. AMA 拟合函数 `ama_fit_example1()`

## 3.1 函数作用

`ama_fit_example1()` 对给定的 \((X, y)\) 完成 AMA 的完整流程：

1. Step 1：通过 LARS 实现 Adaptive LASSO，得到一条解路径；
2. Step 2：用 mBIC 从路径中选出候选变量集合 \(H\)；
3. Step 3–4：围绕 \(H\) 构造一族候选模型，并对每个模型做 OLS 拟合；
4. Step 5–6：在一组 \(\phi_n\) 网格上用 Cp-type 准则选择最优 \(\hat\phi_n\)，得到最终 AMA 模型平均估计 \(\hat\beta(\hat\phi_n)\)。


## 3.2 关键实现源码节选

下面代码块为包内 `R/ama_example1.R` 中 `ama_fit_example1()` 的节选：

```r
ama_fit_example1 <- function(X, y,
                             n_phi_grid = 20,
                             B_mc       = 50,
                             seed       = 2025) {
  step1 <- ama_step1_alasso_lars(X, y, gamma_alasso = 1)
  step2 <- ama_step2_select_H_mBIC(X, y, step1)
  step34 <- ama_step34_build_candidates(X, y, step1, step2)
  step56 <- ama_step5_6_section3(
    X, y,
    step2_res  = step2,
    step34_res = step34,
    n_phi_grid = n_phi_grid,
    B_mc       = B_mc,
    seed       = seed
  )
  
  list(
    beta_ma        = step56$beta_ma,
    phi_hat        = step56$phi_hat,
    w_hat          = step56$w_hat,
    sigma2_hat     = step56$sigma2_hat,
    H              = step2$H,
    candidate_sets = step34$candidate_sets,
    step1          = step1,
    step2          = step2,
    step34         = step34,
    step56         = step56
  )
}


ama_step1_alasso_lars <- function(X, y, gamma_alasso = 1, tol_active = 1e-8) {
  # X: n x p design matrix
  # y: length-n response vector
  # gamma_alasso: exponent in ALASSO weights (default gamma_alasso = 1)
  # tol_active: threshold to decide 'nonzero' coefficients
  
  stopifnot(is.matrix(X), length(y) == nrow(X))
  n <- nrow(X); p <- ncol(X)
  
  if (p >= n) {
    warning("Current p >= n. This violates the Example 1 setting (p < n). OLS init may be unstable.")
  }
  
  ## 0. Preprocessing: scale X and center y
  X_scaled   <- scale(X)
  y_centered <- as.numeric(scale(y, center = TRUE, scale = FALSE))
  
  ## 1. Initial estimator beta^(init): OLS
  lm_init   <- lm(y_centered ~ X_scaled)
  beta_init <- coef(lm_init)[-1]  # drop intercept
  
  ## 2. Build ALASSO weights
  eps     <- 1e-6
  weights <- 1 / (abs(beta_init) + eps)^gamma_alasso
  
  ## 3. Rescale design: X*_j = X_scaled_j / w_j
  X_star <- sweep(X_scaled, 2, weights, FUN = "/")
  
  ## 4. Run LARS-LASSO path on (X*, y_centered)
  if (!requireNamespace("lars", quietly = TRUE)) {
    stop("Package 'lars' is required. Please install it first.")
  }
  
  lars_fit <- lars::lars(
    x          = X_star,
    y          = y_centered,
    type       = "lasso",
    normalize  = FALSE,
    intercept  = TRUE
  )
  
  beta_lars_path   <- lars_fit$beta  # K x p
  beta_alasso_path <- sweep(beta_lars_path, 2, weights, FUN = "/")
  
  ## 5. Extract the active set at each step
  K <- nrow(beta_alasso_path)
  active_sets <- vector("list", K)
  for (k in seq_len(K)) {
    bk <- beta_alasso_path[k, ]
    active_sets[[k]] <- which(abs(bk) > tol_active)
  }
  
  list(
    X_scaled         = X_scaled,
    y_centered       = y_centered,
    beta_init        = beta_init,
    weights          = weights,
    lars_fit         = lars_fit,
    beta_alasso_path = beta_alasso_path,
    active_sets      = active_sets
  )
}
```

## 3.3 基本调用示例

```{r example-ama-fit, echo=TRUE}
# 生成一组 Example 1 数据
dat <- SA25204153:::gen_example1_data(n = 200, rho = 0.5, R2 = 0.4)

# 跑一次 AMA 拟合（为了 vignette 速度，这里减小 MC 次数）
fit_ama <- ama_fit_example1(
  X          = dat$X,
  y          = dat$y,
  n_phi_grid = 5,
  B_mc       = 10,
  seed       = 2025
)

names(fit_ama)
```

返回结果中：

- `beta_ma`：最终 AMA 模型平均估计 \(\hat\beta(\hat\phi_n)\)；
- `phi_hat`：选出的 \(\hat\phi_n\)；
- `w_hat`：候选模型的模型平均权重；
- `sigma2_hat`：基于集合 \(H\) 的噪声方差估计；
- `H`：mBIC 选出的候选变量集合；
- `candidate_sets`：Step 2+3 构造的所有候选模型；
- `step1`, `step2`, `step34`, `step56`：对应各步骤的完整中间结果。

查看非零系数个数：

```{r example-ama-nonzero, echo=TRUE}
sum(abs(fit_ama$beta_ma) > 1e-6)
```

# 4. 模拟主函数 `sim_example1_grid()`

## 4.1 函数作用概述

`sim_example1_grid()` 在一组 \((n, \rho, R^2)\) 组合上重复模拟（默认 `B_rep = 100` 次），比较三种方法的表现：

- 输出指标：
  - MRME：模型误差相对 LS 的中位数；
  - C：真正为零且估计为 0 的系数个数（越大越好）；
  - IC：真正非零却估计为 0 的系数个数（越小越好）。


## 4.2 关键实现源码节选

下面代码块为包内 `R/ama_example1.R` 中 `sim_example1_grid()` 的原样节选：

```r
sim_example1_grid <- function(
    n_vec      = 200,
    rho_vec    = c(0.5, 0.75),
    R2_vec     = c(0.2, 0.4, 0.6, 0.8),
    B_rep      = 100,
    n_phi_grid = 20,
    B_mc       = 50,
    seed       = 2025
) {
  res_all <- data.frame(
    n      = integer(0),
    rho    = numeric(0),
    R2     = numeric(0),
    method = character(0),
    MRME   = numeric(0),
    C      = numeric(0),
    IC     = numeric(0),
    stringsAsFactors = FALSE
  )
  
  for (n in n_vec) {
    for (rho in rho_vec) {
      for (R2 in R2_vec) {
        cat("Running n =", n, ", rho =", rho, ", R2 =", R2, "...\n")
        
        res_one <- sim_example1_one_setting(
          n          = n,
          rho        = rho,
          R2         = R2,
          B_rep      = B_rep,
          n_phi_grid = n_phi_grid,
          B_mc       = B_mc,
          seed       = seed
        )
        
        methods <- names(res_one$MRME)
        
        df_tmp <- data.frame(
          n      = rep(n,    length(methods)),
          rho    = rep(rho,  length(methods)),
          R2     = rep(R2,   length(methods)),
          method = methods,
          MRME   = as.numeric(res_one$MRME),
          C      = as.numeric(res_one$C),
          IC     = as.numeric(res_one$IC),
          stringsAsFactors = FALSE
        )
        
        res_all <- rbind(res_all, df_tmp)
      }
    }
  }
  
  res_all
}
```

## 4.3 精简版示例（vignette 中用较小规模）

为了控制 knit 时间，这里用一个非常小的设定作为演示：

```{r example-sim-grid, echo=TRUE}
res_demo <- sim_example1_grid(
  n_vec      = 200,
  rho_vec    = 0.5,
  R2_vec     = c(0.2, 0.4),
  B_rep      = 10,   # 演示时减小重复次数
  n_phi_grid = 5,
  B_mc       = 10,
  seed       = 2025
)

res_demo
```

### 结果可视化（MRME）

```{r plot-mrme, fig.width=10, fig.height=4.8, out.width="100%", fig.align="center"}
ggplot(res_demo, aes(x = factor(R2), y = MRME, fill = method)) +
  geom_col(position = "dodge") +
  facet_wrap(~ rho, labeller = label_bquote(rho == .(rho))) +
  labs(
    x = expression(R^2),
    y = "MRME（相对 LS 的中位数）",
    title = "不同设定下 MRME 对比"
  ) +
  theme_bw() +
  theme(legend.position = "bottom")
```

# 5. C++ 函数 `compute_ME_cpp()` 与 `compute_C_IC_cpp()`

在 Example 1 的模拟中，我们反复需要计算：

- 模型误差  
  \[
    ME(\hat\beta) = (\hat\beta - \beta_0)^\top \Sigma (\hat\beta - \beta_0),
  \]
- 稀疏性指标 C / IC：
  - C：真零系数中被估计为 0 的个数；
  - IC：真正非零却被估计为 0 的个数。

为了提高效率，这两个计算被实现为 Rcpp 函数：

- `compute_ME_cpp(beta_hat, beta0, Sigma)`
- `compute_C_IC_cpp(beta_hat, beta0, tol = 1e-6)`

下面给出可直接复现的最小示例，并在 vignette 内部提供一个“纯 R”版本用于速度对比。


## 5.1 C++ 源码

下面代码块为包内 `src/ama_utils.cpp` 的原样节选，其中包含 `compute_ME_cpp()` 与 `compute_C_IC_cpp()` 的 C++/Rcpp 实现

```cpp
#include <Rcpp.h>
using namespace Rcpp;

// [[Rcpp::export]]
double compute_ME_cpp(const NumericVector& beta_hat,
                      const NumericVector& beta0,
                      const NumericMatrix& Sigma) {
  int p = beta_hat.size();
  if (beta0.size() != p) stop("beta_hat and beta0 must have the same length.");
  if (Sigma.nrow() != p || Sigma.ncol() != p) stop("Sigma must be a p x p matrix.");
  
  double me = 0.0;
  for (int i = 0; i < p; ++i) {
    double di = beta_hat[i] - beta0[i];
    double s  = 0.0;
    for (int j = 0; j < p; ++j) {
      s += Sigma(i, j) * (beta_hat[j] - beta0[j]);
    }
    me += di * s;
  }
  return me;
}

// [[Rcpp::export]]
NumericVector compute_C_IC_cpp(const NumericVector& beta_hat,
                               const NumericVector& beta0,
                               double tol = 1e-6) {
  int p = beta_hat.size();
  if (beta0.size() != p) stop("beta_hat and beta0 must have the same length.");
  
  int C = 0, IC = 0;
  for (int j = 0; j < p; ++j) {
    bool true_zero = std::fabs(beta0[j]) < tol;
    bool est_zero  = std::fabs(beta_hat[j]) < tol;
    if (true_zero && est_zero)  ++C;
    if (!true_zero && est_zero) ++IC;
  }
  
  NumericVector out = NumericVector::create(_["C"] = C, _["IC"] = IC);
  return out;
}
```

## 5.2 `compute_ME_cpp()` 示例

```{r rcpp-me-example, echo=TRUE}
beta0 <- dat$beta0
Sigma <- dat$Sigma

ME_ama <- compute_ME_cpp(fit_ama$beta_ma, beta0, Sigma)
ME_ama
```

## 5.3 `compute_C_IC_cpp()` 示例

```{r rcpp-cic-example, echo=TRUE}
CIC_ama <- compute_C_IC_cpp(fit_ama$beta_ma, beta0)
CIC_ama
```

## 5.4 速度对比：R vs Rcpp（microbenchmark）

为了做速度对比，这里在 vignette 内写一个“纯 R”的对照版本。

```{r rcpp-speed-compare, echo=TRUE}
compute_ME_R <- function(beta_hat, beta0, Sigma) {
  diff <- beta_hat - beta0
  as.numeric(t(diff) %*% Sigma %*% diff)
}

compute_C_IC_R <- function(beta_hat, beta0, tol = 1e-6) {
  is_zero_true <- abs(beta0) < tol
  is_zero_hat  <- abs(beta_hat) < tol
  c(C = sum(is_zero_true & is_zero_hat),
    IC = sum(!is_zero_true & is_zero_hat))
}

# 构造一组随机输入，避免基准测试被“特例”影响
set.seed(123)
p <- length(beta0)
beta_hat_test <- beta0 + rnorm(p, 0, 0.2)

mb <- microbenchmark(
  ME_R     = compute_ME_R(beta_hat_test, beta0, Sigma),
  ME_cpp   = compute_ME_cpp(beta_hat_test, beta0, Sigma),
  C_IC_R   = compute_C_IC_R(beta_hat_test, beta0),
  C_IC_cpp = compute_C_IC_cpp(beta_hat_test, beta0),
  times = 200L
)
mb
```

```{r rcpp-speed-summary, echo=FALSE}
mb_sum <- summary(mb)[, c("expr", "median", "mean", "min", "max")]
knitr::kable(mb_sum, digits = 0,
             caption = "R vs Rcpp：microbenchmark 结果摘要（单位：microseconds）")
```

# 6. 小结

本 vignette 简要说明了课程大作业中实现的 AMA Example 1 数值实验代码，包括：

- `ama_fit_example1()`：在单个数据集上完成 AMA Step 1–6 的拟合，并返回 AMA 估计与各步骤中间结果；
- `sim_example1_grid()`：在一组 \((n, \rho, R^2)\) 设定下进行 Monte Carlo 模拟，对比 AMA 与基于 ALASSO 的两种单模型选择方法；
- `compute_ME_cpp()` 与 `compute_C_IC_cpp()`：在 C++ 中高效计算模型误差和稀疏性指标，用于支持大规模模拟。
